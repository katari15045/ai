{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_neural_network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "x9TyZ_wJafwd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1hyplUw5bEQr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Constants:\n",
        "  \n",
        "  SIGMOID = \"sigmoid\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZvmNBiwWy0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "  \n",
        "  # name of the activation function\n",
        "  act_func = None \n",
        "  in_edges = None\n",
        "  out_edges = None\n",
        "  # output of a neuron i.e activation(summation(w_i*x_i))\n",
        "  output = None       \n",
        "  # error at a neuron during back propagation\n",
        "  local_error = None  \n",
        "  # input to the input-layer-neuron\n",
        "  input_datum = None   \n",
        "  # loss for output-layer-neuron at the end of forward propagation\n",
        "  forward_prop_loss = None   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4zEiitEIeV4Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neuron(Neuron):\n",
        "  \n",
        "  # returns output of activation function\n",
        "  def apply_act_func(self, inp):\n",
        "    if(self.act_func == Constants.SIGMOID):\n",
        "      return ( 1/ ( 1+numpy.exp(-1*inp) ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIv5_eBleba0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neuron(Neuron):\n",
        "  \n",
        "  # returns derivative of activation function\n",
        "  def apply_act_func_der(self, inp):\n",
        "    if(self.act_func == Constants.SIGMOID):\n",
        "      return (inp*(1-inp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fc24bQtkeQLv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neuron(Neuron):\n",
        "  \n",
        "  # forward propagation (computes output of a neuron)\n",
        "  # assumption-1: outputs of start_neurons of all self.in_edges are calculated\n",
        "  # assumption-2: self.input_datum is initialized for a first-layered-neuron\n",
        "  def forward_prop(self):\n",
        "    # first-layered-neuron\n",
        "    if(self.in_edges == None): \n",
        "      self.output = self.input_datum\n",
        "      return\n",
        "    output = 0.0\n",
        "    ind = 0\n",
        "    # compute summation(w_i*x_i)\n",
        "    while(ind < len(self.in_edges)):\n",
        "      edge = self.in_edges[ind]\n",
        "      weight = edge.weight\n",
        "      inp = edge.start_neuron.output\n",
        "      output = output + (weight*inp)\n",
        "      ind = ind + 1\n",
        "    # apply activation function\n",
        "    self.output = self.apply_act_func(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "67yQsGVugbiu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neuron(Neuron):\n",
        "  \n",
        "  # back propagation (updates the weights of in_edges)\n",
        "  # local_error: before multiplying by weight\n",
        "  # assumption-1: local_errors of all end_neurons of self.out_edges are calculated\n",
        "  # assumption-2: self.output is computed\n",
        "  # assumption-3: self.forward_prop_loss is initialized for an output-layered-neuron\n",
        "  def back_prop(self, local_error):\n",
        "    # output-layered-neuron\n",
        "    if(self.out_edges == None): \n",
        "      local_error_self = self.forward_prop_loss\n",
        "    else:\n",
        "      ind = 0\n",
        "      local_error_self = 0.0\n",
        "      # compute self.local_error\n",
        "      while(ind < len(self.out_edges)):\n",
        "        edge = self.out_edges[ind]\n",
        "        weight = edge.weight\n",
        "        local_error_other = edge.end_neuron.local_error\n",
        "        local_error_self = local_error_self + (local_error_other * weight)\n",
        "        ind = ind + 1\n",
        "    act_func_der = self.apply_act_func_der(self.output)\n",
        "    self.local_error = local_error_self * act_func_der\n",
        "    # update self.in_edges\n",
        "    ind = 0\n",
        "    while(ind < len(self.in_edges)):\n",
        "      edge = self.in_edges[ind]\n",
        "      inp = edge.start_neuron.output\n",
        "      update = self.local_error * inp\n",
        "      self.in_edges[ind].weight = edge.weight + update\n",
        "      ind = ind + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NUqospJjTMx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# An edge between 2 neurons\n",
        "class Edge:\n",
        "  \n",
        "  start_neuron = None\n",
        "  end_neuron = None\n",
        "  weight = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ICgspVoQzGhi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fully connected Layer\n",
        "class Layer:\n",
        "  \n",
        "  tot_neurons = None\n",
        "  act_func = None\n",
        "  neurons = None\n",
        "  prev_layer = None\n",
        "  next_layer = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I-ro1iF60hiz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Layer(Layer):\n",
        "  \n",
        "  # add in_edges to cur_layer's neurons & out_edges to prev_layer's neurons\n",
        "  # assumption: should have non-None value to self.prev_layer from 2nd layer onwards\n",
        "  def build(self):\n",
        "    # cur refers to current layer\n",
        "    cur_neuron_ind = 0 \n",
        "    self.neurons = []\n",
        "    # add neurons\n",
        "    while(cur_neuron_ind < self.tot_neurons):\n",
        "      cur_neuron = Neuron()\n",
        "      cur_neuron.act_func = self.act_func\n",
        "      # add in_edges to cur_neuron\n",
        "      if(self.prev_layer != None):\n",
        "        cur_neuron.in_edges = []\n",
        "        prev_neuron_ind = 0\n",
        "        while(prev_neuron_ind < self.prev_layer.tot_neurons):\n",
        "          prev_neuron = self.prev_layer.neurons[prev_neuron_ind]\n",
        "          edge = Edge\n",
        "          edge.start_neuron = prev_neuron\n",
        "          edge.end_neuron = cur_neuron\n",
        "          edge.weight = 0.5\n",
        "          cur_neuron.in_edges.append(edge)\n",
        "          prev_neuron_ind = prev_neuron_ind + 1\n",
        "      self.neurons.append(cur_neuron)\n",
        "      cur_neuron_ind = cur_neuron_ind + 1\n",
        "    # add out_edges to prev_layer's neurons\n",
        "    if(self.prev_layer != None):\n",
        "      prev_neuron_ind = 0\n",
        "      while(prev_neuron_ind < self.prev_layer.tot_neurons):\n",
        "        prev_neuron = self.prev_layer.neurons[prev_neuron_ind]\n",
        "        prev_neuron.out_edges = []\n",
        "        cur_neuron_ind = 0\n",
        "        # add out_edges to prev_neuron\n",
        "        while(cur_neuron_ind < self.tot_neurons):\n",
        "          cur_neuron = self.neurons[cur_neuron_ind]\n",
        "          edge = Edge\n",
        "          edge.start_neuron = prev_neuron\n",
        "          edge.end_neuron = cur_neuron\n",
        "          edge.weight = 0.5\n",
        "          prev_neuron.out_edges.append(edge)\n",
        "          cur_neuron_ind = cur_neuron_ind + 1\n",
        "        prev_neuron_ind = prev_neuron_ind + 1\n",
        "    \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4mmMfHnjUnTd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neural_Network:\n",
        "  \n",
        "  # including input, hidden and output layers\n",
        "  tot_layers = None\n",
        "  # a list containing no. of neurons in each layer\n",
        "  tot_neurons = None\n",
        "  # single activation func; ex: Constants.SIGMOID\n",
        "  act_func = None\n",
        "  # a list containing actual layers\n",
        "  layers = None\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IFfCfhGdVaHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neural_Network(Neural_Network):\n",
        "  \n",
        "  def build(self):\n",
        "    cur_layer_ind = 0\n",
        "    prev_layer_ind = -1\n",
        "    self.layers = []\n",
        "    while(cur_layer_ind < self.tot_layers):\n",
        "      cur_layer = Layer()\n",
        "      cur_layer.tot_neurons = self.tot_neurons[cur_layer_ind]\n",
        "      cur_layer.act_func = self.act_func\n",
        "      if(prev_layer_ind != -1):\n",
        "        cur_layer.prev_layer = self.layers[prev_layer_ind]\n",
        "      cur_layer.build()\n",
        "      self.layers.append(cur_layer)\n",
        "      cur_layer_ind = cur_layer_ind + 1\n",
        "      prev_layer_ind = prev_layer_ind + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1tp1iYluZa1T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neural_Network(Neural_Network):\n",
        "  \n",
        "  def print(self):\n",
        "    print(\"layers: \" + str(self.tot_layers))\n",
        "    print(\"neurons: \" + str(self.tot_neurons))\n",
        "    print(\"activation: \" + str(self.act_func))\n",
        "    print(\"=======================\")\n",
        "    print(\"layer.neuron.edge: weight\")\n",
        "    layer_ind = 0\n",
        "    while(layer_ind < self.tot_layers):\n",
        "      cur_layer = self.layers[layer_ind]\n",
        "      neuron_ind = 0\n",
        "      while(neuron_ind < cur_layer.tot_neurons):\n",
        "        cur_neuron = cur_layer.neurons[neuron_ind]\n",
        "        if(cur_neuron.out_edges != None):\n",
        "          out_edge_ind = 0\n",
        "          while(out_edge_ind < len(cur_neuron.out_edges)):\n",
        "            out_edge = cur_neuron.out_edges[out_edge_ind]\n",
        "            print(str(layer_ind) + \".\" + str(neuron_ind) + \".\" + str(out_edge_ind) + \": \" + str(out_edge.weight))\n",
        "            out_edge_ind = out_edge_ind + 1\n",
        "        neuron_ind = neuron_ind + 1\n",
        "      layer_ind = layer_ind + 1\n",
        "      if(layer_ind != self.tot_layers):\n",
        "        print(\"=======================\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I1ggFPg5YPQk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Main:\n",
        "  \n",
        "  @staticmethod\n",
        "  def main():\n",
        "    nn = Neural_Network()\n",
        "    nn.tot_layers = 3\n",
        "    nn.tot_neurons = [2, 4, 1]\n",
        "    nn.act_func = Constants.SIGMOID\n",
        "    nn.build()\n",
        "    nn.print()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxQdZg2abgHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "f8a0c544-cbcd-45a1-d5b8-18c179ce828e"
      },
      "cell_type": "code",
      "source": [
        "start_time = time()\n",
        "Main.main()\n",
        "end_time = time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"processed in \" + str(elapsed_time) + \" seconds.\")"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layers: 3\n",
            "neurons: [2, 4, 1]\n",
            "activation: sigmoid\n",
            "=======================\n",
            "layer.neuron.edge: weight\n",
            "0.0.0: 0.5\n",
            "0.0.1: 0.5\n",
            "0.0.2: 0.5\n",
            "0.0.3: 0.5\n",
            "0.1.0: 0.5\n",
            "0.1.1: 0.5\n",
            "0.1.2: 0.5\n",
            "0.1.3: 0.5\n",
            "=======================\n",
            "1.0.0: 0.5\n",
            "1.1.0: 0.5\n",
            "1.2.0: 0.5\n",
            "1.3.0: 0.5\n",
            "=======================\n",
            "processed in 0.004755973815917969 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}